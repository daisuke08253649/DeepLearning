{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1z4ryh4XTrfXCzR0FITXO8eORPt9Kz0u1",
      "authorship_tag": "ABX9TyPrte/Pf07mnbCemYT5rgbR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisuke08253649/DeepLearning/blob/main/Defect_detection_in_cast_products.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "def unzip_dataset(INPATH, OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "\n",
        "unzip_dataset(INPATH='./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/train_data.zip', OUTPATH='./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products')\n",
        "\n",
        "#image_name_list = os.listdir('./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/train_data')\n",
        "#print(image_name_list)"
      ],
      "metadata": {
        "id": "df6lFEQmw7ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "\n",
        "image_files = glob.glob('./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/train_data/*')\n",
        "label_datas = pd.read_csv('./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/train.csv')\n",
        "\n",
        "images = []\n",
        "for file in image_files:\n",
        "    img = io.imread(file)\n",
        "    images.append(img)\n",
        "image_datas = np.array(images)\n",
        "image_datas = image_datas / 255\n",
        "#print(image_datas)\n",
        "\n",
        "labels = []\n",
        "for label in label_datas.target:\n",
        "    labels.append(label)\n",
        "labels_lists = labels\n",
        "#print(labels_dummy)\n",
        "\n",
        "\n",
        "#plt.figure(figsize=(30, 30))\n",
        "#for i in range(250):\n",
        "    #plt.subplot(10, 25, i+1)\n",
        "    #plt.title(datas.target[i])\n",
        "    #plt.imshow(train_image[i])\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "ZlXb_vn8l73O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "target_num = 2\n",
        "\n",
        "def get_model(target_num, ispretrained=False):\n",
        "    model_ft = models.resnet18(pretrained=ispretrained)\n",
        "    model_ft.fc = nn.Linear(512, target_num)\n",
        "    model_ft = model_ft.to(device)\n",
        "    return model_ft\n",
        "\n",
        "model = get_model(target_num, ispretrained=False)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZfHyMew5sTx",
        "outputId": "c077d44b-74a8-4775-b5de-fb60c9c450ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=3, shuffle=True, random_state=32)\n",
        "for fold,(train_index, val_index) in enumerate(kf.split(image_datas, labels_lists)):\n",
        "    #print(f'Fold:{fold}, train_index:{len(train_index)}, val_index:{len(val_index)}')\n",
        "\n",
        "    X_train = image_datas[train_index].transpose(0, 3, 1, 2)\n",
        "    X_val = image_datas[val_index].transpose(0, 3, 1, 2)\n",
        "    y_train = np.array(labels_lists)[train_index]\n",
        "    y_val = np.array(labels_lists)[val_index]\n",
        "\n",
        "\n",
        "    x_tr = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_tr = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "    x_vl = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_vl = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "\n",
        "    train_dataset = TensorDataset(x_tr, y_tr)\n",
        "    val_dataset = TensorDataset(x_vl, y_vl)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(50):\n",
        "    train_loss_total = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        train_loss = criterion(output, labels)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_total += train_loss.item() * inputs.size(0)\n",
        "\n",
        "    train_loss_avg = train_loss_total / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "\n",
        "    val_loss_total = 0.0\n",
        "    val_corrects = 0\n",
        "\n",
        "    model.eval()\n",
        "    for i, (inputs, labels) in enumerate(val_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).long()\n",
        "\n",
        "        val_output = model(inputs)\n",
        "        _, val_preds = torch.max(val_output, 1)\n",
        "        loss = criterion(val_output, labels)\n",
        "        val_loss_total += loss.item() * inputs.size(0)\n",
        "        val_corrects += torch.sum(val_preds == labels.data)\n",
        "\n",
        "    val_loss_avg = val_loss_total / len(val_loader.dataset)\n",
        "    val_corrects = val_corrects.double() / len(val_loader.dataset)\n",
        "\n",
        "    print(f'epoch:{epoch}, train_loss:{train_loss_avg:.4f}, val_loss:{val_loss_avg:.4f}, acc:{val_corrects}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6RJFDHF2d9r",
        "outputId": "16e62ff4-a7a3-4d1a-f49e-190afb40064d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0, train_loss:0.8926, val_loss:0.8719, acc:0.39759036144578314\n",
            "epoch:1, train_loss:0.6988, val_loss:1.0319, acc:0.6024096385542169\n",
            "epoch:2, train_loss:0.6329, val_loss:0.8164, acc:0.6024096385542169\n",
            "epoch:3, train_loss:0.5988, val_loss:0.8325, acc:0.6024096385542169\n",
            "epoch:4, train_loss:0.5890, val_loss:1.0102, acc:0.4096385542168675\n",
            "epoch:5, train_loss:0.5297, val_loss:0.9925, acc:0.6144578313253012\n",
            "epoch:6, train_loss:0.3784, val_loss:3.0960, acc:0.3855421686746988\n",
            "epoch:7, train_loss:0.5169, val_loss:14.3174, acc:0.39759036144578314\n",
            "epoch:8, train_loss:0.3519, val_loss:1.0597, acc:0.5542168674698795\n",
            "epoch:9, train_loss:0.3694, val_loss:2.7846, acc:0.6024096385542169\n",
            "epoch:10, train_loss:0.2437, val_loss:1.3251, acc:0.5180722891566265\n",
            "epoch:11, train_loss:0.3214, val_loss:1.2941, acc:0.5060240963855422\n",
            "epoch:12, train_loss:0.2024, val_loss:1.3183, acc:0.6144578313253012\n",
            "epoch:13, train_loss:0.2386, val_loss:5.3399, acc:0.3855421686746988\n",
            "epoch:14, train_loss:0.1823, val_loss:5.5035, acc:0.3734939759036145\n",
            "epoch:15, train_loss:0.1341, val_loss:1.8318, acc:0.6506024096385542\n",
            "epoch:16, train_loss:0.1084, val_loss:1.9774, acc:0.5542168674698795\n",
            "epoch:17, train_loss:0.0561, val_loss:1.7444, acc:0.5903614457831325\n",
            "epoch:18, train_loss:0.0857, val_loss:1.9391, acc:0.5542168674698795\n",
            "epoch:19, train_loss:0.0338, val_loss:1.7332, acc:0.5301204819277109\n",
            "epoch:20, train_loss:0.0715, val_loss:2.1119, acc:0.6024096385542169\n",
            "epoch:21, train_loss:0.0491, val_loss:2.4770, acc:0.5783132530120483\n",
            "epoch:22, train_loss:0.0659, val_loss:2.1697, acc:0.6385542168674699\n",
            "epoch:23, train_loss:0.1070, val_loss:2.3336, acc:0.5180722891566265\n",
            "epoch:24, train_loss:0.1099, val_loss:3.3676, acc:0.45783132530120485\n",
            "epoch:25, train_loss:0.3866, val_loss:2.9784, acc:0.43373493975903615\n",
            "epoch:26, train_loss:0.1351, val_loss:1.4455, acc:0.6506024096385542\n",
            "epoch:27, train_loss:0.0731, val_loss:1.7424, acc:0.6385542168674699\n",
            "epoch:28, train_loss:0.0712, val_loss:2.0022, acc:0.5542168674698795\n",
            "epoch:29, train_loss:0.0279, val_loss:1.8087, acc:0.5903614457831325\n",
            "epoch:30, train_loss:0.0226, val_loss:1.7138, acc:0.5783132530120483\n",
            "epoch:31, train_loss:0.0069, val_loss:1.8086, acc:0.5903614457831325\n",
            "epoch:32, train_loss:0.0067, val_loss:1.7928, acc:0.6024096385542169\n",
            "epoch:33, train_loss:0.0076, val_loss:1.7194, acc:0.5783132530120483\n",
            "epoch:34, train_loss:0.0193, val_loss:2.1162, acc:0.5903614457831325\n",
            "epoch:35, train_loss:0.0057, val_loss:2.3063, acc:0.5783132530120483\n",
            "epoch:36, train_loss:0.0040, val_loss:2.3921, acc:0.5542168674698795\n",
            "epoch:37, train_loss:0.0921, val_loss:3.5245, acc:0.5421686746987953\n",
            "epoch:38, train_loss:0.0554, val_loss:2.0664, acc:0.5903614457831325\n",
            "epoch:39, train_loss:0.0345, val_loss:1.6393, acc:0.5542168674698795\n",
            "epoch:40, train_loss:0.0262, val_loss:1.6651, acc:0.5783132530120483\n",
            "epoch:41, train_loss:0.0082, val_loss:1.8734, acc:0.6024096385542169\n",
            "epoch:42, train_loss:0.0070, val_loss:2.0032, acc:0.6024096385542169\n",
            "epoch:43, train_loss:0.0115, val_loss:2.2249, acc:0.5421686746987953\n",
            "epoch:44, train_loss:0.0225, val_loss:2.6485, acc:0.5662650602409639\n",
            "epoch:45, train_loss:0.0560, val_loss:2.5591, acc:0.5542168674698795\n",
            "epoch:46, train_loss:0.0809, val_loss:1.7009, acc:0.6385542168674699\n",
            "epoch:47, train_loss:0.2037, val_loss:1.9543, acc:0.5903614457831325\n",
            "epoch:48, train_loss:0.2528, val_loss:3.1324, acc:0.5301204819277109\n",
            "epoch:49, train_loss:0.1004, val_loss:4.1441, acc:0.4096385542168675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), './drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/model.pth')"
      ],
      "metadata": {
        "id": "sPkaWURwHFqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip_dataset(INPATH, OUTPATH):\n",
        "    with zipfile.ZipFile(INPATH) as zf:\n",
        "        zf.extractall(OUTPATH)\n",
        "\n",
        "unzip_dataset(INPATH='./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/test_data.zip', OUTPATH='./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products')\n",
        "test_image_list = os.listdir('./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/test_data')\n",
        "\n",
        "df_test = pd.DataFrame(data=test_image_list)\n",
        "\n",
        "df_test = df_test.rename(columns={0: 'filename'})\n",
        "\n",
        "df_test['target'] = 0\n",
        "df_test.loc[df_test['filename'].str.contains('ok'), 'target'] = 1\n",
        "\n",
        "df_test.to_csv('sample_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "6ZrdOpGzrwEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406] , [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "class Test_dataset(Dataset):\n",
        "    def __init__(self, transform):\n",
        "        self.df = pd.read_csv('./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/sample_submission.csv')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file = self.df['filename'][index]\n",
        "        image = Image.open('./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/test_data/' + file)\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return image, file\n",
        "\n",
        "test_dataset = Test_dataset(test_transforms)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "8JwXrHKT8J6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(512, 2)\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "model.load_state_dict(torch.load('./drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/model.pth'))\n",
        "\n",
        "pred = []\n",
        "for i, (inputs, labels) in enumerate(test_dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    output = model(inputs)\n",
        "    _, preds = torch.max(output, 1)\n",
        "\n",
        "    pred.extend(preds.cpu().numpy().tolist())\n",
        "\n",
        "df_test['target'] = pred\n",
        "\n",
        "data_csv = './drive/MyDrive/DeepLearning/SIGNATE/Defect_detection_in_cast_products/sample_submission.csv'\n",
        "\n",
        "with open(data_csv, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "lines.pop(0)\n",
        "\n",
        "df_test.to_csv(data_csv, index=False, header=False, mode='w')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH5Bz9RkGmzv",
        "outputId": "5fd166ca-fdf1-4904-8575-facee6260f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyB1xOv0LF2u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}