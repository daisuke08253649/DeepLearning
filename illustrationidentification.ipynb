{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisuke08253649/DeepLearning/blob/main/illustrationidentification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIjHuVooAEso",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30n7GkkjoLC_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "model_list = timm.list_models(pretrained=True)\n",
        "print(model_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w3cbDI4-cNAU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs-FtoYR6aN8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "train_image_dir = './drive/MyDrive/DeepLearning/illustrationdiscrimination/data/train'\n",
        "val_image_dir = './drive/MyDrive/DeepLearning/illustrationdiscrimination/data/val'\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "}\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_image_dir, transform=data_transforms['train'])\n",
        "val_dataset = torchvision.datasets.ImageFolder(root=val_image_dir, transform=data_transforms['val'])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=80, shuffle=True)\n",
        "test_dataloader = DataLoader(val_dataset, batch_size=20, shuffle=True)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGFKNqbKBKjF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, criterion, optimizer, train_losses):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss = train_loss / len(train_dataloader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "def val(model, val_dataloader, criterion, val_losses, val_accuracies):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_accuracy = 0\n",
        "\n",
        "    for inputs, labels in val_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        val_loss += loss.item()\n",
        "        val_accuracy += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_dataloader)\n",
        "    val_accuracy = val_accuracy / len(val_dataloader.dataset)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b45_cFcYodrC",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "model = timm.create_model('vit_base_patch16_clip_224.openai_ft_in12k_in1k', pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "lr = 1e-3\n",
        "epochs = 50\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, criterion, optimizer, train_losses)\n",
        "    val_loss, val_accuracy = val(model, val_dataloader, criterion, val_losses, val_accuracies)\n",
        "\n",
        "    print(f'Epoch: {i+1}, Train_loss: {train_loss}, Val_loss: {val_loss}, Val_accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "id": "ZuGhpucXBTkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(range(1, len(train_loss_list)+1), train_loss_list, label='train_loss')\n",
        "plt.plot(range(1, len(test_loss_list)+1), test_loss_list, label='test_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5u-HQAOO-Qmw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "test_iter = iter(test_dataloader)\n",
        "true_list = []\n",
        "false_list = []\n",
        "input, label = next(test_iter)\n",
        "output = model(Variable(input.cuda()))\n",
        "_, predict = torch.max(output.data, 1)\n",
        "\n",
        "for idx in range(len(label)):\n",
        "    lst = [input[idx], label[idx], predict[idx]]\n",
        "    if int(label[idx]) == int(predict[idx]):\n",
        "        true_list.append(lst)\n",
        "    else:\n",
        "        false_list.append(lst)\n",
        "\n",
        "print(f'予測が正解しているデータ:{len(true_list)}')\n",
        "for idx, tlst in enumerate(true_list[:5]):\n",
        "    plt.figure(idx+1)\n",
        "    image = tlst[0].cpu().numpy()\n",
        "    if image.ndim == 3 and image.shape[0] == 3:\n",
        "        image = image.transpose((1, 2, 0))\n",
        "    plt.imshow(image, cmap='Blues')\n",
        "    plt.title('True: {}, Estim: {}'.format(tlst[1], tlst[2]))"
      ],
      "metadata": {
        "id": "ccj0ybu3xwPD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'予測が不正解のデータ:{len(false_list)}')\n",
        "for idx, flst in enumerate(false_list[:5]):\n",
        "    plt.figure(idx+1)\n",
        "    image = flst[0].cpu().numpy()\n",
        "    if image.ndim == 3 and image.shape[0] == 3:\n",
        "        image = image.transpose((1, 2, 0))\n",
        "    plt.imshow(image, cmap='Reds')\n",
        "    plt.title('True: {}, Estim: {}'.format(flst[1], flst[2]))"
      ],
      "metadata": {
        "id": "plbNbjCVyPqD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XwHgtS1KQpe"
      },
      "outputs": [],
      "source": [
        "#モデル保存\n",
        "torch.save(model, 'illustrationidentification_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VCDk11raI4L"
      },
      "outputs": [],
      "source": [
        "#モデルロード\n",
        "model = torch.load('./保存されたモデルのパス')\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1_6hfBn9BeXOD0SoAS5-fnaQKaYktgbo-",
      "authorship_tag": "ABX9TyOgFR0AT+0HuOqggqIYyupl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}